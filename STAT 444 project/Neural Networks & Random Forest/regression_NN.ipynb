{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set options\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "data_raw = pd.read_csv(\"STAT_444_project_data_power_transformed_noNA.csv\", low_memory = True)\n",
    "\n",
    "\n",
    "#data_raw.dropna()\n",
    "data_raw.reset_index(drop=True, inplace=True)\n",
    "\n",
    "##train_raw, test_raw = train_test_split(data_raw, test_size=0.1)\n",
    "\n",
    "\n",
    "split_index = int(0.9 * len(data_raw))  # 80% for training, 20% for testing\n",
    "train_raw = data_raw[:split_index] \n",
    "test_raw = data_raw[split_index:]\n",
    "\n",
    "\n",
    "#train_x_raw = pd.read_csv(\"../01-Data/X_train.csv\", low_memory = True, index_col=0)\n",
    "#train_y_raw = pd.read_csv(\"../01-Data/y_train.csv\", low_memory = True, index_col=0)\n",
    "#test_x_raw = pd.read_csv(\"../01-Data/X_test.csv\", low_memory=True, index_col=0)\n",
    "\n",
    "df_train = pd.DataFrame(train_raw).drop([\"date_1\",\"date_2\", \"temp2_c\", \"temp2_min_c\",\n",
    "            \"wind_speed50_ave_m_s\", \"max_generation_mw\"], axis=1)\n",
    "df_test = pd.DataFrame(test_raw).drop([\"date_1\",\"date_2\", \"temp2_c\", \"temp2_min_c\",\n",
    "            \"wind_speed50_ave_m_s\", \"max_generation_mw\"], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_z_scaled = df_train.copy()\n",
    "df_tz = df_test.copy()\n",
    "# apply normalization techniques \n",
    "for column in df_z_scaled.columns:\n",
    "    df_z_scaled[column] = df_z_scaled[column].astype(float)\n",
    "    df_z_scaled[column] = (df_z_scaled[column] -\n",
    "                           df_z_scaled[column].mean()) / (df_z_scaled[column].std())\n",
    "\n",
    "for column in df_tz.columns:\n",
    "    df_tz[column] = df_tz[column].astype(float)\n",
    "    df_tz[column] = (df_tz[column] -\n",
    "                           df_tz[column].mean()) / (df_tz[column].std())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xtrain = df_z_scaled.drop(['total_demand_mw'], axis=1)\n",
    "df_xtest = df_tz.drop(['total_demand_mw'], axis=1)\n",
    "df_ytrain = df_z_scaled['total_demand_mw']\n",
    "df_ytest = df_tz['total_demand_mw']\n",
    "\n",
    "\n",
    "df_tensor_xtr = torch.tensor(df_xtrain.values, dtype=torch.float32)\n",
    "df_tensor_xte = torch.tensor(df_xtest.values, dtype=torch.float32)\n",
    "df_tensor_ytr = torch.tensor(df_ytrain.values, dtype=torch.float32)\n",
    "df_tensor_yte = torch.tensor(df_ytest.values, dtype=torch.float32)\n",
    "df_tensor_xtr = torch.nan_to_num(df_tensor_xtr)\n",
    "df_tensor_xte = torch.nan_to_num(df_tensor_xte )\n",
    "df_tensor_ytr = torch.nan_to_num(df_tensor_ytr)\n",
    "df_tensor_yte = torch.nan_to_num(df_tensor_yte )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5872, -1.6987, -1.3900,  ..., -0.3921, -1.8925, -1.1784],\n",
       "        [-1.4965, -1.6987, -1.3900,  ...,  0.2090, -0.2405, -0.9279],\n",
       "        [-1.4010, -1.6987, -1.3900,  ...,  0.5878,  0.8182, -0.5870],\n",
       "        ...,\n",
       "        [-0.1068,  1.0704,  1.5058,  ..., -0.0843,  0.4492, -0.0071],\n",
       "        [ 0.0079,  1.0704,  1.5058,  ..., -0.1262, -0.0597, -0.2682],\n",
       "        [ 0.1234,  1.0704,  1.5058,  ...,  0.0711, -0.0221,  0.4999]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tensor_xtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.x = df_tensor_xtr\n",
    "        self.t = df_tensor_ytr\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.t[idx]\n",
    "    \n",
    "    def inputs(self):\n",
    "        return self.x\n",
    "    \n",
    "    def targets(self):\n",
    "        return self.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class datasett(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.x = df_tensor_xte\n",
    "        self.t = df_tensor_yte\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.t[idx]\n",
    "    \n",
    "    def inputs(self):\n",
    "        return self.x\n",
    "    \n",
    "    def targets(self):\n",
    "        return self.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size_train = 256\n",
    "#train_dl = torch.utils.data.DataLoader(dataset(), batch_size=batch_size_train, shuffle=True)\n",
    "test_all = torch.utils.data.DataLoader(datasett(), batch_size=len(df_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "    print(f'Reset trainable parameters of layer = {layer}')\n",
    "    layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressorNN(nn.Module):\n",
    "    '''\n",
    "     \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "        super().__init__()\n",
    "        \n",
    "        #===== YOUR CODE HERE =====\n",
    "        self.seq= nn.Sequential(\n",
    "            nn.Linear(9, 32),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(8, 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #===== YOUR CODE HERE =====\n",
    "        x = self.seq(x)\n",
    "        return x  # replace this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "k_folds = 5\n",
    "num_epochs = 2000\n",
    "# Set fixed random number seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Reset trainable parameters of layer = Linear(in_features=9, out_features=32, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=1, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([120])) that is different to the input size (torch.Size([120, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 2000/2000 [00:56<00:00, 35.15it/s]\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([95])) that is different to the input size (torch.Size([95, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss for fold 1: 0.9846925139427185\n",
      "Fold 2\n",
      "Reset trainable parameters of layer = Linear(in_features=9, out_features=32, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=1, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([121])) that is different to the input size (torch.Size([121, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 2000/2000 [00:59<00:00, 33.50it/s]\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([94])) that is different to the input size (torch.Size([94, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss for fold 2: 0.8944589495658875\n",
      "Fold 3\n",
      "Reset trainable parameters of layer = Linear(in_features=9, out_features=32, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=1, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:01<00:00, 32.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss for fold 3: 1.1008175611495972\n",
      "Fold 4\n",
      "Reset trainable parameters of layer = Linear(in_features=9, out_features=32, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=1, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:01<00:00, 32.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss for fold 4: 0.9762589037418365\n",
      "Fold 5\n",
      "Reset trainable parameters of layer = Linear(in_features=9, out_features=32, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=1, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:00<00:00, 33.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss for fold 5: 0.9557713568210602\n",
      "Final CV Loss: 0.98239985704422\n"
     ]
    }
   ],
   "source": [
    "all_val_losses = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(dataset())):\n",
    "    print(f'Fold {fold+1}')\n",
    "    \n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset(), batch_size=256, sampler=train_sampler)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset(), batch_size=256, sampler=val_sampler)\n",
    "    \n",
    "    net1 = RegressorNN()\n",
    "    if torch.cuda.is_available():\n",
    "      net1 = net1.cuda()\n",
    "    net1.apply(reset_weights)\n",
    "    optimizer = torch.optim.SGD(net1.parameters(), lr=0.00001, momentum=0.8)\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        net1.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = net1(X_batch)\n",
    "            loss = loss_fn(predictions, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    net1.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            predictions = net1(X_batch)\n",
    "            loss = loss_fn(predictions, y_batch)\n",
    "            val_losses.append(loss.item())\n",
    "    fold_val_loss = np.mean(val_losses)\n",
    "    all_val_losses.append(fold_val_loss)\n",
    "    print(f'Validation Loss for fold {fold+1}: {np.mean(val_losses)}')\n",
    "\n",
    "\n",
    "mean_cv_loss = np.mean(all_val_losses)\n",
    "std_cv_loss = np.std(all_val_losses)\n",
    "\n",
    "print(f'Final CV Loss: {mean_cv_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

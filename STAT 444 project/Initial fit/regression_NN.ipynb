{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>temp2_max_c</th>\n",
       "      <th>temp2_ave_c</th>\n",
       "      <th>surface_pressure_pa</th>\n",
       "      <th>wind_speed50_max_m_s</th>\n",
       "      <th>wind_speed50_min_m_s</th>\n",
       "      <th>prectotcorr</th>\n",
       "      <th>total_demand_mw</th>\n",
       "      <th>max_generation_mw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>11.211578</td>\n",
       "      <td>6.809483</td>\n",
       "      <td>-8.840693e-34</td>\n",
       "      <td>9173.644062</td>\n",
       "      <td>4.311080e+11</td>\n",
       "      <td>1.136752e+20</td>\n",
       "      <td>2.301639</td>\n",
       "      <td>0.972103</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>38.796139</td>\n",
       "      <td>-0.158464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>12.589254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.753636e-34</td>\n",
       "      <td>6130.530937</td>\n",
       "      <td>8.903655e+10</td>\n",
       "      <td>1.144632e+20</td>\n",
       "      <td>2.091786</td>\n",
       "      <td>1.164213</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>39.147977</td>\n",
       "      <td>-0.159749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>2.143547</td>\n",
       "      <td>6.809483</td>\n",
       "      <td>-8.753636e-34</td>\n",
       "      <td>9072.726139</td>\n",
       "      <td>6.562704e+11</td>\n",
       "      <td>1.104622e+20</td>\n",
       "      <td>3.439450</td>\n",
       "      <td>1.366268</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>42.414245</td>\n",
       "      <td>-0.153287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.143547</td>\n",
       "      <td>1.741101</td>\n",
       "      <td>-8.928703e-34</td>\n",
       "      <td>5589.762571</td>\n",
       "      <td>5.917282e+10</td>\n",
       "      <td>1.120030e+20</td>\n",
       "      <td>1.851023</td>\n",
       "      <td>0.792186</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>35.483341</td>\n",
       "      <td>-0.168962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>16.801099</td>\n",
       "      <td>4.192963</td>\n",
       "      <td>-8.840693e-34</td>\n",
       "      <td>9541.061003</td>\n",
       "      <td>1.637914e+12</td>\n",
       "      <td>9.980018e+19</td>\n",
       "      <td>3.830037</td>\n",
       "      <td>1.620657</td>\n",
       "      <td>3.060046</td>\n",
       "      <td>40.241941</td>\n",
       "      <td>-0.156318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>9.849155</td>\n",
       "      <td>2.408225</td>\n",
       "      <td>-8.797046e-34</td>\n",
       "      <td>12795.958602</td>\n",
       "      <td>9.489104e+11</td>\n",
       "      <td>1.118923e+20</td>\n",
       "      <td>3.578425</td>\n",
       "      <td>0.857917</td>\n",
       "      <td>0.831224</td>\n",
       "      <td>40.832416</td>\n",
       "      <td>-0.154347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>26.985657</td>\n",
       "      <td>5.278032</td>\n",
       "      <td>-8.797046e-34</td>\n",
       "      <td>9970.881089</td>\n",
       "      <td>1.377687e+12</td>\n",
       "      <td>1.061646e+20</td>\n",
       "      <td>3.884985</td>\n",
       "      <td>1.641728</td>\n",
       "      <td>1.551119</td>\n",
       "      <td>41.452351</td>\n",
       "      <td>-0.153719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>4.594793</td>\n",
       "      <td>4.192963</td>\n",
       "      <td>-8.840693e-34</td>\n",
       "      <td>11702.912265</td>\n",
       "      <td>1.980164e+12</td>\n",
       "      <td>1.038656e+20</td>\n",
       "      <td>3.398117</td>\n",
       "      <td>1.464875</td>\n",
       "      <td>2.696504</td>\n",
       "      <td>37.762534</td>\n",
       "      <td>-0.160545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>8.503698</td>\n",
       "      <td>1.741101</td>\n",
       "      <td>-8.753636e-34</td>\n",
       "      <td>3860.334426</td>\n",
       "      <td>9.837790e+09</td>\n",
       "      <td>1.158256e+20</td>\n",
       "      <td>2.545942</td>\n",
       "      <td>1.206570</td>\n",
       "      <td>0.251189</td>\n",
       "      <td>39.041613</td>\n",
       "      <td>-0.160198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>2.143547</td>\n",
       "      <td>2.408225</td>\n",
       "      <td>-8.797046e-34</td>\n",
       "      <td>13269.656642</td>\n",
       "      <td>8.753139e+11</td>\n",
       "      <td>1.109005e+20</td>\n",
       "      <td>2.675852</td>\n",
       "      <td>1.272013</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>40.472847</td>\n",
       "      <td>-0.156074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1704 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            day     month          year   temp2_max_c   temp2_ave_c  \\\n",
       "1013  11.211578  6.809483 -8.840693e-34   9173.644062  4.311080e+11   \n",
       "1432  12.589254  1.000000 -8.753636e-34   6130.530937  8.903655e+10   \n",
       "1715   2.143547  6.809483 -8.753636e-34   9072.726139  6.562704e+11   \n",
       "32     2.143547  1.741101 -8.928703e-34   5589.762571  5.917282e+10   \n",
       "869   16.801099  4.192963 -8.840693e-34   9541.061003  1.637914e+12   \n",
       "...         ...       ...           ...           ...           ...   \n",
       "1130   9.849155  2.408225 -8.797046e-34  12795.958602  9.489104e+11   \n",
       "1294  26.985657  5.278032 -8.797046e-34   9970.881089  1.377687e+12   \n",
       "860    4.594793  4.192963 -8.840693e-34  11702.912265  1.980164e+12   \n",
       "1459   8.503698  1.741101 -8.753636e-34   3860.334426  9.837790e+09   \n",
       "1126   2.143547  2.408225 -8.797046e-34  13269.656642  8.753139e+11   \n",
       "\n",
       "      surface_pressure_pa  wind_speed50_max_m_s  wind_speed50_min_m_s  \\\n",
       "1013         1.136752e+20              2.301639              0.972103   \n",
       "1432         1.144632e+20              2.091786              1.164213   \n",
       "1715         1.104622e+20              3.439450              1.366268   \n",
       "32           1.120030e+20              1.851023              0.792186   \n",
       "869          9.980018e+19              3.830037              1.620657   \n",
       "...                   ...                   ...                   ...   \n",
       "1130         1.118923e+20              3.578425              0.857917   \n",
       "1294         1.061646e+20              3.884985              1.641728   \n",
       "860          1.038656e+20              3.398117              1.464875   \n",
       "1459         1.158256e+20              2.545942              1.206570   \n",
       "1126         1.109005e+20              2.675852              1.272013   \n",
       "\n",
       "      prectotcorr  total_demand_mw  max_generation_mw  \n",
       "1013     0.003981        38.796139          -0.158464  \n",
       "1432     0.003981        39.147977          -0.159749  \n",
       "1715     0.003981        42.414245          -0.153287  \n",
       "32       0.003981        35.483341          -0.168962  \n",
       "869      3.060046        40.241941          -0.156318  \n",
       "...           ...              ...                ...  \n",
       "1130     0.831224        40.832416          -0.154347  \n",
       "1294     1.551119        41.452351          -0.153719  \n",
       "860      2.696504        37.762534          -0.160545  \n",
       "1459     0.251189        39.041613          -0.160198  \n",
       "1126     0.003981        40.472847          -0.156074  \n",
       "\n",
       "[1704 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set options\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "data_raw = pd.read_csv(\"STAT_444_project_data_power_transformed.csv\", low_memory = True)\n",
    "\n",
    "#data_raw.dropna()\n",
    "data_raw.reset_index(drop=True, inplace=True)\n",
    "train_raw, test_raw = train_test_split(data_raw, test_size=0.1, random_state=42)\n",
    "#train_x_raw = pd.read_csv(\"../01-Data/X_train.csv\", low_memory = True, index_col=0)\n",
    "#train_y_raw = pd.read_csv(\"../01-Data/y_train.csv\", low_memory = True, index_col=0)\n",
    "#test_x_raw = pd.read_csv(\"../01-Data/X_test.csv\", low_memory=True, index_col=0)\n",
    "\n",
    "\n",
    "\n",
    "df_train = pd.DataFrame(train_raw).drop([\"date_1\",\"date_2\", \"temp2_c\", \"temp2_min_c\",\n",
    "            \"wind_speed50_ave_m_s\"], axis=1)\n",
    "df_test = pd.DataFrame(test_raw).drop([\"date_1\",\"date_2\", \"temp2_c\", \"temp2_min_c\",\n",
    "            \"wind_speed50_ave_m_s\"], axis=1)\n",
    "\n",
    "\n",
    "len(df_train.columns)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_z_scaled = df_train.copy()\n",
    "df_tz = df_test.copy()\n",
    "# apply normalization techniques \n",
    "for column in df_z_scaled.columns:\n",
    "    df_z_scaled[column] = df_z_scaled[column].astype(float)\n",
    "    df_z_scaled[column] = (df_z_scaled[column] -\n",
    "                           df_z_scaled[column].mean()) / (df_z_scaled[column].std())\n",
    "\n",
    "for column in df_tz.columns:\n",
    "    df_tz[column] = df_tz[column].astype(float)\n",
    "    df_tz[column] = (df_tz[column] -\n",
    "                           df_tz[column].mean()) / (df_tz[column].std())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xtrain = df_z_scaled.drop(['total_demand_mw'], axis=1)\n",
    "df_xtest = df_tz.drop(['total_demand_mw'], axis=1)\n",
    "df_ytrain = df_z_scaled['total_demand_mw']\n",
    "df_ytest = df_tz['total_demand_mw']\n",
    "\n",
    "\n",
    "df_tensor_xtr = torch.tensor(df_xtrain.values, dtype=torch.float32)\n",
    "df_tensor_xte = torch.tensor(df_xtest.values, dtype=torch.float32)\n",
    "df_tensor_ytr = torch.tensor(df_ytrain.values, dtype=torch.float32)\n",
    "df_tensor_yte = torch.tensor(df_ytest.values, dtype=torch.float32)\n",
    "df_tensor_xtr = torch.nan_to_num(df_tensor_xtr)\n",
    "df_tensor_xte = torch.nan_to_num(df_tensor_xte )\n",
    "df_tensor_ytr = torch.nan_to_num(df_tensor_ytr)\n",
    "df_tensor_yte = torch.nan_to_num(df_tensor_yte )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1131,  1.6514, -0.7596,  ..., -1.1180, -0.5416, -1.7044],\n",
       "        [ 1.5039, -0.9312, -0.1149,  ...,  0.4594, -0.5416, -0.3560],\n",
       "        [-0.5442, -1.5051,  1.1745,  ..., -0.6835, -0.4981, -0.4646],\n",
       "        ...,\n",
       "        [-0.6580, -0.3573, -0.1149,  ..., -0.9394,  0.2176, -0.1865],\n",
       "        [ 1.6177,  1.6514,  0.5298,  ..., -0.4037, -0.5416, -0.7082],\n",
       "        [ 1.7314, -1.5051,  0.5298,  ..., -0.0882, -0.5416, -0.7737]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tensor_xtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.x = df_tensor_xtr\n",
    "        self.t = df_tensor_ytr\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.t[idx]\n",
    "    \n",
    "    def inputs(self):\n",
    "        return self.x\n",
    "    \n",
    "    def targets(self):\n",
    "        return self.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class datasett(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.x = df_tensor_xte\n",
    "        self.t = df_tensor_yte\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.t[idx]\n",
    "    \n",
    "    def inputs(self):\n",
    "        return self.x\n",
    "    \n",
    "    def targets(self):\n",
    "        return self.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size_train = 256\n",
    "#train_dl = torch.utils.data.DataLoader(dataset(), batch_size=batch_size_train, shuffle=True)\n",
    "test_all = torch.utils.data.DataLoader(datasett(), batch_size=len(df_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "    print(f'Reset trainable parameters of layer = {layer}')\n",
    "    layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressorNN(nn.Module):\n",
    "    '''\n",
    "     \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "        super().__init__()\n",
    "        \n",
    "        #===== YOUR CODE HERE =====\n",
    "        self.seq= nn.Sequential(\n",
    "            nn.Linear(10, 32),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(8, 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #===== YOUR CODE HERE =====\n",
    "        x = self.seq(x)\n",
    "        return x  # replace this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "k_folds = 5\n",
    "num_epochs = 2000\n",
    "# Set fixed random number seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=32, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=1, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([83])) that is different to the input size (torch.Size([83, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 2000/2000 [00:57<00:00, 34.80it/s]\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([85])) that is different to the input size (torch.Size([85, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss for fold 1: 1.021453619003296\n",
      "Fold 2\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=32, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=1, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:59<00:00, 33.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss for fold 2: 1.126146912574768\n",
      "Fold 3\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=32, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=1, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:02<00:00, 31.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss for fold 3: 0.9771924018859863\n",
      "Fold 4\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=32, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=1, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:05<00:00, 30.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss for fold 4: 1.0633456408977509\n",
      "Fold 5\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=32, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=1, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([84])) that is different to the input size (torch.Size([84, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 2000/2000 [01:07<00:00, 29.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss for fold 5: 0.9734272062778473\n",
      "Final CV Loss: 1.0323131561279297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_val_losses = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(dataset())):\n",
    "    print(f'Fold {fold+1}')\n",
    "    \n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset(), batch_size=256, sampler=train_sampler)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset(), batch_size=256, sampler=val_sampler)\n",
    "    \n",
    "    net1 = RegressorNN()\n",
    "    if torch.cuda.is_available():\n",
    "      net1 = net1.cuda()\n",
    "    net1.apply(reset_weights)\n",
    "    optimizer = torch.optim.SGD(net1.parameters(), lr=0.00001, momentum=0.8)\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        net1.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = net1(X_batch)\n",
    "            loss = loss_fn(predictions, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    net1.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            predictions = net1(X_batch)\n",
    "            loss = loss_fn(predictions, y_batch)\n",
    "            val_losses.append(loss.item())\n",
    "    fold_val_loss = np.mean(val_losses)\n",
    "    all_val_losses.append(fold_val_loss)\n",
    "    print(f'Validation Loss for fold {fold+1}: {np.mean(val_losses)}')\n",
    "\n",
    "\n",
    "mean_cv_loss = np.mean(all_val_losses)\n",
    "std_cv_loss = np.std(all_val_losses)\n",
    "\n",
    "print(f'Final CV Loss: {mean_cv_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
